SimCLR Training Log
MESSAGE: final
BATCH_SIZE: 64
EPOCHS: 100
TEMPERATURE: 0.2
LEARNING_RATE: 0.0003
DEVICE: cuda
MODEL_SAVE_DIR: saved_models
----------------------------------------

Epoch 1: loss = 3.4962
Epoch 2: loss = 2.7701
Epoch 3: loss = 2.5208
Epoch 4: loss = 2.3849
Epoch 5: loss = 2.2921
Epoch 6: loss = 2.2312
Epoch 7: loss = 2.1792
Epoch 8: loss = 2.1307
Epoch 9: loss = 2.0919
Epoch 10: loss = 2.0631
Epoch 11: loss = 2.0436
Epoch 12: loss = 2.0058
Epoch 13: loss = 1.9887
Epoch 14: loss = 1.9726
Epoch 15: loss = 1.9598
Epoch 16: loss = 1.9416
Epoch 17: loss = 1.9266
Epoch 18: loss = 1.9180
Epoch 19: loss = 1.9018
Epoch 20: loss = 1.8925
Epoch 21: loss = 1.8793
Epoch 22: loss = 1.8722
Epoch 23: loss = 1.8618
Epoch 24: loss = 1.8471
Epoch 25: loss = 1.8321
Epoch 26: loss = 1.8377
Epoch 27: loss = 1.8264
Epoch 28: loss = 1.8106
Epoch 29: loss = 1.8019
Epoch 30: loss = 1.8049
Epoch 31: loss = 1.7915
Epoch 32: loss = 1.7843
Epoch 33: loss = 1.7781
Epoch 34: loss = 1.7817
Epoch 35: loss = 1.7727
Epoch 36: loss = 1.7699
Epoch 37: loss = 1.7551
Epoch 38: loss = 1.7568
Epoch 39: loss = 1.7471
Epoch 40: loss = 1.7471
Epoch 41: loss = 1.7426
Epoch 42: loss = 1.7295
Epoch 43: loss = 1.7314
Epoch 44: loss = 1.7377
Epoch 45: loss = 1.7229
Epoch 46: loss = 1.7220
Epoch 47: loss = 1.7080
Epoch 48: loss = 1.7088
Epoch 49: loss = 1.7050
Epoch 50: loss = 1.7046
Epoch 51: loss = 1.7058
Epoch 52: loss = 1.7032
Epoch 53: loss = 1.6951
Epoch 54: loss = 1.6857
Epoch 55: loss = 1.6775
Epoch 56: loss = 1.6753
Epoch 57: loss = 1.6810
Epoch 58: loss = 1.6706
Epoch 59: loss = 1.6654
Epoch 60: loss = 1.6646
Epoch 61: loss = 1.6638
Epoch 62: loss = 1.6605
Epoch 63: loss = 1.6504
Epoch 64: loss = 1.6530
Epoch 65: loss = 1.6493
Epoch 66: loss = 1.6446
Epoch 67: loss = 1.6419
Epoch 68: loss = 1.6417
Epoch 69: loss = 1.6384
Epoch 70: loss = 1.6391
Epoch 71: loss = 1.6412
Epoch 72: loss = 1.6382
Epoch 73: loss = 1.6310
Epoch 74: loss = 1.6362
Epoch 75: loss = 1.6223
Epoch 76: loss = 1.6265
Epoch 77: loss = 1.6189
Epoch 78: loss = 1.6170
Epoch 79: loss = 1.6106
Epoch 80: loss = 1.6153
Epoch 81: loss = 1.6124
Epoch 82: loss = 1.6064
Epoch 83: loss = 1.6095
Epoch 84: loss = 1.6045
Epoch 85: loss = 1.6078
Epoch 86: loss = 1.5911
Epoch 87: loss = 1.5974
Epoch 88: loss = 1.5994
Epoch 89: loss = 1.5911
Epoch 90: loss = 1.5893
Epoch 91: loss = 1.5886
Epoch 92: loss = 1.5892
Epoch 93: loss = 1.5931
Epoch 94: loss = 1.5846
Epoch 95: loss = 1.5817
Epoch 96: loss = 1.5842
Epoch 97: loss = 1.5794
Epoch 98: loss = 1.5809
Epoch 99: loss = 1.5721
Epoch 100: loss = 1.5752
Linear Epoch 1: loss = 0.6860
Linear Epoch 2: loss = 0.5958
Linear Epoch 3: loss = 0.5771
Linear Epoch 4: loss = 0.5643
Linear Epoch 5: loss = 0.5620
Linear Epoch 6: loss = 0.5504
Linear Epoch 7: loss = 0.5436
Linear Epoch 8: loss = 0.5418
Linear Epoch 9: loss = 0.5387
Linear Epoch 10: loss = 0.5340
Linear Epoch 11: loss = 0.5361
Linear Epoch 12: loss = 0.5278
Linear Epoch 13: loss = 0.5302
Linear Epoch 14: loss = 0.5277
Linear Epoch 15: loss = 0.5251
Linear Epoch 16: loss = 0.5245
Linear Epoch 17: loss = 0.5226
Linear Epoch 18: loss = 0.5220
Linear Epoch 19: loss = 0.5177
Linear Epoch 20: loss = 0.5188
Linear Epoch 21: loss = 0.5157
Linear Epoch 22: loss = 0.5182
Linear Epoch 23: loss = 0.5155
Linear Epoch 24: loss = 0.5159
Linear Epoch 25: loss = 0.5126
Linear Epoch 26: loss = 0.5133
Linear Epoch 27: loss = 0.5147
Linear Epoch 28: loss = 0.5118
Linear Epoch 29: loss = 0.5093
Linear Epoch 30: loss = 0.5107
Linear Epoch 31: loss = 0.5083
Linear Epoch 32: loss = 0.5142
Linear Epoch 33: loss = 0.5099
Linear Epoch 34: loss = 0.5065
Linear Epoch 35: loss = 0.5078
Linear Epoch 36: loss = 0.5020
Linear Epoch 37: loss = 0.5104
Linear Epoch 38: loss = 0.5083
Linear Epoch 39: loss = 0.5080
Linear Epoch 40: loss = 0.5072
Linear Epoch 41: loss = 0.5063
Linear Epoch 42: loss = 0.5085
Linear Epoch 43: loss = 0.5047
Linear Epoch 44: loss = 0.5045
Linear Epoch 45: loss = 0.5062
Linear Epoch 46: loss = 0.5061
Linear Epoch 47: loss = 0.5040
Linear Epoch 48: loss = 0.5051
Linear Epoch 49: loss = 0.5037
Linear Epoch 50: loss = 0.5049
Linear Evaluation Test Accuracy: 82.16%
